query,answer,doc
What is an AI accelerator?,"An AI accelerator, also referred to as deep learning processor, or neural processing unit (NPU), is a class of specialized hardware accelerator or computer system designed to accelerate artificial intelligence and machine learning applications, including artificial neural networks and machine vision.",AI accelerator.txt
Where are AI accelerators often used?,"AI accelerators are used in various devices, including mobile devices such as neural processing units (NPUs) in Apple iPhones or Huawei cellphones, and personal computers such as Apple silicon Macs, to cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform. ",AI accelerator.txt
How have GPUs been utilized for AI acceleration?,"Graphics processing units or GPUs, that are specialized hardware for the manipulation of images and calculation of local image properties, have been increasingly used for machine learning tasks. GPU developers have also incorporated neural network-specific hardware to further accelerate these tasks.",AI accelerator.txt
What has been the progress of AI accelerator technology in the 1990s?,"In the 1990s, attempts were made to create high-throughput parallel systems for workstations aimed at various applications, including neural network simulations. FPGA-based accelerators for both inference and training were first explored in the 1990s.",AI accelerator.txt
What is the difference between CPUs and AI accelerators in terms of performing AI-related tasks?,"While CPUs are used for running AI workloads and are superior for DNNs with small or medium-scale parallelism, for sparse DNNs and in low-batch-size scenarios, specialized AI accelerators like GPUs and FPGAs perform far better due to their optimized memory use and the use of lower precision arithmetic to accelerate calculation and increase throughput of computation. In fact, ASICs, a specific design of accelerators, may provide up to 10 times the efficiency of CPUs for AI-related tasks.",AI accelerator.txt